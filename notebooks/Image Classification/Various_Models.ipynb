{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO111s4xV0lt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "def is_running_in_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if is_running_in_colab():\n",
        "  # Normal packages\n",
        "  %pip install lightning polars segmentation_models_pytorch\n",
        "  # Dev packages\n",
        "  %pip install icecream rich tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.io import decode_image\n",
        "from torchvision.transforms import v2\n",
        "import lightning as L\n",
        "from lightning.pytorch.callbacks import RichProgressBar\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "import torchmetrics\n",
        "\n",
        "# Dev Imports\n",
        "from icecream import ic\n",
        "\n",
        "class PlantVillageData(L.LightningDataModule):\n",
        "  def __init__(self, ws_root: Path = Path(\".\"), num_workers=0):\n",
        "    super().__init__()\n",
        "    metadata_path = ws_root / 'plantvillage_dataset' / 'metadata'\n",
        "    self.train_ds = ImageDataset(pl.read_csv(metadata_path / 'resampled_training_set.csv').filter(pl.col('image_path').str.contains('augment').eq(False)), training=True)\n",
        "    self.val_ds = ImageDataset(pl.read_csv(metadata_path / 'validation_set.csv'))\n",
        "    self.test_ds = ImageDataset(pl.read_csv(metadata_path / 'test_set.csv'))\n",
        "\n",
        "    self.n_classes = len(self.train_ds.disease_to_idx)\n",
        "    self.idx_to_disease = {v:k for k,v in self.train_ds.disease_to_idx.items()}\n",
        "\n",
        "    self.dataloader_extras = dict(\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = True,\n",
        "        persistent_workers = num_workers > 0\n",
        "    )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.train_ds, batch_size=32, shuffle=True, **self.dataloader_extras)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.val_ds, batch_size=64, **self.dataloader_extras)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.test_ds, batch_size=64, **self.dataloader_extras)\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataframe: pl.DataFrame, training=False):\n",
        "    super().__init__()\n",
        "    self.image_path = dataframe.select('image_path').to_numpy().squeeze().copy()\n",
        "    self.disease_type = dataframe.select('disease_type').to_numpy().squeeze().copy()\n",
        "    self.disease_to_idx = {disease: i for i, disease in enumerate(np.unique(self.disease_type))}\n",
        "\n",
        "    self.training = training\n",
        "    self.train_transforms = v2.Compose([\n",
        "        v2.RandomHorizontalFlip(),\n",
        "        v2.RandomVerticalFlip(),\n",
        "        v2.RandomErasing(),\n",
        "    ])\n",
        "    self.transforms = v2.Compose([\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_path)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = decode_image(self.image_path[idx])\n",
        "    if self.training:\n",
        "      image = self.train_transforms(image)\n",
        "    image = self.transforms(image)\n",
        "    disease = self.disease_to_idx[self.disease_type[idx]]\n",
        "    return image, disease\n",
        "\n",
        "def channel_shuffle(x, groups=2):\n",
        "  bat_size, channels, w, h = x.shape\n",
        "  group_c = channels // groups\n",
        "  x = x.view(bat_size, groups, group_c, w, h)\n",
        "  x = torch.transpose(x, 1, 2).contiguous()\n",
        "  x = x.view(bat_size, -1, w, h)\n",
        "  return x\n",
        "\n",
        "class ShuffleBlock(nn.Module):\n",
        "  def __init__(self, in_c, out_c, downsample=False):\n",
        "    super().__init__()\n",
        "    self.downsample = downsample\n",
        "    half_c = out_c // 2\n",
        "    if downsample:\n",
        "      self.branch1 = nn.Sequential(\n",
        "          # 3*3 dw conv, stride = 2\n",
        "          nn.Conv2d(in_c, in_c, 3, 2, 1, groups=in_c, bias=False),\n",
        "          nn.BatchNorm2d(in_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(in_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "      self.branch2 = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(in_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True),\n",
        "          # 3*3 dw conv, stride = 2\n",
        "          nn.Conv2d(half_c, half_c, 3, 2, 1, groups=half_c, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "    else:\n",
        "      # in_c = out_c\n",
        "      assert in_c == out_c\n",
        "\n",
        "      self.branch2 = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True),\n",
        "          # 3*3 dw conv, stride = 1\n",
        "          nn.Conv2d(half_c, half_c, 3, 1, 1, groups=half_c, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = None\n",
        "    if self.downsample:\n",
        "      # if it is downsampling, we don't need to do channel split\n",
        "      out = torch.cat((self.branch1(x), self.branch2(x)), 1)\n",
        "    else:\n",
        "      # channel split\n",
        "      channels = x.shape[1]\n",
        "      c = channels // 2\n",
        "      x1 = x[:, :c, :, :]\n",
        "      x2 = x[:, c:, :, :]\n",
        "      new_x2 = self.branch2(x2)\n",
        "      x2 = x2 + new_x2 # Residual connection\n",
        "      out = torch.cat((x1, x2), 1)\n",
        "    return channel_shuffle(out, 2)\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, num_classes=2):\n",
        "    super().__init__()\n",
        "\n",
        "    self.stage_repeat_num = [4, 8, 4]\n",
        "    self.out_channels = [3, 24, 48, 96, 192, 1024]\n",
        "    # self.out_channels = [3, 24, 116, 232, 464, 1024]\n",
        "    # self.out_channels = [3, 24, 176, 352, 704, 1024]\n",
        "    # self.out_channels = [3, 24, 244, 488, 976, 2948]\n",
        "\n",
        "    # let's start building layers\n",
        "    self.conv1 = nn.Conv2d(3, self.out_channels[1], 3, 2, 1)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    in_c = self.out_channels[1]\n",
        "\n",
        "    self.stages = []\n",
        "    for stage_idx in range(len(self.stage_repeat_num)):\n",
        "      out_c = self.out_channels[2+stage_idx]\n",
        "      repeat_num = self.stage_repeat_num[stage_idx]\n",
        "      for i in range(repeat_num):\n",
        "        if i == 0:\n",
        "          self.stages.append(ShuffleBlock(in_c, out_c, downsample=True))\n",
        "        else:\n",
        "          self.stages.append(ShuffleBlock(in_c, in_c, downsample=False))\n",
        "        in_c = out_c\n",
        "    self.stages = nn.Sequential(*self.stages)\n",
        "\n",
        "    in_c = self.out_channels[-2]\n",
        "    out_c = self.out_channels[-1]\n",
        "    self.conv5 = nn.Sequential(\n",
        "      nn.Conv2d(in_c, out_c, 1, 1, 0, bias=False),\n",
        "      nn.BatchNorm2d(out_c),\n",
        "      nn.ReLU(True)\n",
        "    )\n",
        "\n",
        "    # fc layer\n",
        "    self.fc = nn.Linear(out_c, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.stages(x)\n",
        "    x = self.conv5(x)\n",
        "    x = x.mean(-1).mean(-1)\n",
        "    x = x.view(-1, self.out_channels[-1])\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "class WrappedModel(torch.nn.Module):\n",
        "  def __init__(self, n_classes, model_type):\n",
        "    super().__init__()\n",
        "\n",
        "    model_dict = {\n",
        "      \"ShuffleNetV2\": \"shufflenet_v2_x0_5\",\n",
        "      \"ResNet50\": \"resnet50\",\n",
        "      \"MobileNetV2\": \"mobilenet_v2\",\n",
        "    }\n",
        "\n",
        "    if model_type in model_dict:\n",
        "      self.model = torch.hub.load(\"pytorch/vision\", model_dict[model_type], weights=None)\n",
        "    else:\n",
        "      raise Error(f\"model_type {model_type} not supported\")\n",
        "    self.out_layer = torch.nn.Linear(1000, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    x = self.out_layer(x)\n",
        "    return x\n",
        "\n",
        "class LitWrappedModel(L.LightningModule):\n",
        "  def __init__(self, n_classes, model_type):\n",
        "    super().__init__()\n",
        "    if model_type == \"Custom\":\n",
        "      self.model = CustomModel(num_classes = n_classes)\n",
        "    else:\n",
        "      self.model = WrappedModel(n_classes, model_type)\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "    self.val_metrics = torchmetrics.MetricCollection(\n",
        "        {\n",
        "            \"accuracy\": torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=n_classes),\n",
        "            \"f1\": torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=n_classes),\n",
        "            \"auroc\": torchmetrics.classification.AUROC(task=\"multiclass\", num_classes=n_classes)\n",
        "        },\n",
        "        prefix=\"val_\",\n",
        "    )\n",
        "    self.test_metrics = self.val_metrics.clone(prefix=\"test_\")\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_pred = self.model(x)\n",
        "    loss = torch.nn.functional.cross_entropy(y_pred, y)\n",
        "    self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_pred = self.model(x)\n",
        "    self.log_dict(self.val_metrics(y_pred, y), prog_bar=True)\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_pred = self.model(x)\n",
        "    self.log_dict(self.test_metrics(y_pred, y), prog_bar=True)\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    L.pytorch.utilities.memory.garbage_collection_cuda()\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "plantvillage_data = PlantVillageData(num_workers=15)\n",
        "\n",
        "for exp_name in (\"Custom\", \"ShuffleNetV2\", \"ResNet50\", \"MobileNetV2\"):\n",
        "  lit_model = LitWrappedModel(plantvillage_data.n_classes, model_type=exp_name)\n",
        "\n",
        "  trainer = L.Trainer(\n",
        "      max_epochs=50,\n",
        "      accelerator='gpu',\n",
        "      callbacks=[RichProgressBar()],\n",
        "      logger=CSVLogger(\"csv_logs/classification\", name=exp_name, version=0),\n",
        "  )\n",
        "  trainer.fit(model=lit_model, datamodule=plantvillage_data)\n",
        "\n",
        "  model_save_path = Path(\"models\") / \"classification\"\n",
        "  model_save_path = model_save_path / exp_name\n",
        "  model_save_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  model = lit_model.model\n",
        "  model = model.eval().cpu()\n",
        "  ## Save just weights\n",
        "  torch.save(model.state_dict(), model_save_path / f\"weights_{exp_name}.pt\")\n",
        "  ## Pickle the whole model\n",
        "  torch.save(model, model_save_path / f\"model_{exp_name}.pt\")\n",
        "  ## Using experimental torch export\n",
        "  _height = torch.export.Dim('_height', min=1)\n",
        "  _width = torch.export.Dim('_width', min=1)\n",
        "  dynamic_shapes = {\"x\": {\n",
        "    0: torch.export.Dim(\"batch\", min=1, max=9223372036854775806),\n",
        "    2: 32*_height,\n",
        "    3: 32*_width,\n",
        "  }}\n",
        "  ep = torch.export.export(model, (torch.randn(2, 3, 512, 512),), dynamic_shapes=dynamic_shapes, strict=True)\n",
        "  torch.export.save(ep, model_save_path / f\"export_{exp_name}.pt2\")\n",
        "\n",
        "  trainer.test(model=lit_model, datamodule=plantvillage_data)"
      ],
      "metadata": {
        "id": "Zerl0QQNhVUD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}